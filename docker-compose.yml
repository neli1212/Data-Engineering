version: '3.8'

services:
  nyc_ingestion:
    build: ./services/ingestion
    image: nyc_ingestion:latest
    profiles: ["build-only"] 

  nyc_processing:
    build: ./services/processing
    image: nyc_processing:latest
    profiles: ["build-only"]
    
  minio:
    image: minio/minio:latest
    container_name: minio
    ports: ["9000:9000", "9001:9001"]
    command: server /data --console-address ":9001"
    networks: [data_network]

  postgres:
    image: postgres:13
    container_name: airflow_postgres
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    networks: [data_network]

  spark-master:
    image: apache/spark:3.5.0
    container_name: spark_master
    hostname: spark-master 
    ports:
      - "8080:8080"
      - "7077:7077"
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master -h spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
    networks:
      data_network:
        aliases:
          - spark-master 

  spark-worker:
    image: apache/spark:3.5.0
    container_name: spark_worker
    depends_on:
      - spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=4G
      - SPARK_EXECUTOR_MEMORY=2G
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD}
    networks:
      - data_network

  airflow-init:
    image: apache/airflow:2.8.1
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    entrypoint: /bin/bash -c "airflow db migrate && airflow users create --username admin --password admin --firstname Peter --lastname Parker --role Admin --email admin@example.com"
    networks: [data_network]

  airflow-webserver:
    image: apache/airflow:2.8.1
    container_name: airflow_webserver
    depends_on: [airflow-init]
    command: webserver
    user: "50000:0"
    group_add:
      - "${DOCKER_GID}"  
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__WEBSERVER__SECRET_KEY: "secret"
      _PIP_ADDITIONAL_REQUIREMENTS: "apache-airflow-providers-docker boto3"
    ports: ["8081:8080"]
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs  
      - /var/run/docker.sock:/var/run/docker.sock
    networks: [data_network]

  airflow-scheduler:
    image: apache/airflow:2.8.1
    container_name: airflow_scheduler
    depends_on: [airflow-init]
    command: scheduler
    user: "50000:0"
    group_add:
      - "${DOCKER_GID}"  
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__WEBSERVER__SECRET_KEY: "secret"
      _PIP_ADDITIONAL_REQUIREMENTS: "apache-airflow-providers-docker boto3"
      AIRFLOW_PROJ_DIR: ${PWD}
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs  
      - /var/run/docker.sock:/var/run/docker.sock
    networks: [data_network]

networks:
  data_network:
    name: nyc_data_network
    driver: bridge